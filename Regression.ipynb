{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2J\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy  as np \n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(chr(27) + \"[2J\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv(\"train.csv\");\n",
    "dataTest  = pd.read_csv( \"test.csv\");\n",
    "\n",
    "# Nan to zero\n",
    "dataTrain.fillna(0);\n",
    "dataTest .fillna(0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definir features\n",
    "tr = ['SalePrice']\n",
    "\n",
    "catOrdinal = ['MSZoning','Street','Alley','LandContour','Utilities','LotConfig','Neighborhood','Condition1','Condition2',\n",
    "              'BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation','Heating',\n",
    "              'CentralAir','Electrical','Functional','GarageType','MiscFeature','SaleType','SaleCondition']\n",
    "\n",
    "catNominal = {'LotShape':['Reg','IR1','IR2','IR3','NA'],\n",
    "              'LandSlope':['Gtl','Mod','Sev','NA'],\n",
    "              'ExterQual':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'ExterCond':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'BsmtQual':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'BsmtCond':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'BsmtExposure':['Gd','Av','Mn','No','NA'],\n",
    "              'BsmtFinType1':['GLQ','ALQ','BLQ','Rec','LwQ','Unf','NA'],\n",
    "              'BsmtFinType2':['GLQ','ALQ','BLQ','Rec','LwQ','Unf','NA'],\n",
    "              'HeatingQC':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'KitchenQual':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'FireplaceQu':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'GarageQual':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'GarageCond':['Ex','Gd','TA','Fa','Po','NA'],\n",
    "              'PavedDrive':['Y','P','N'],\n",
    "              'PoolQC':['Ex','Gd','TA','Fa','NA'],\n",
    "              'Fence':['GdPrv','MnPrv','GdWo','MnWw','NA']}\n",
    "\n",
    "nu = ['MSSubClass','LotFrontage','LotArea','OverallQual','OverallCond','YearBuilt','YearRemodAdd','MasVnrArea','BsmtFinSF1',\n",
    "      'BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath',\n",
    "      'FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea',\n",
    "      'WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold','SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir datos categoricos a numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ordinal\n",
    "for cat in catOrdinal:\n",
    "    \n",
    "    # Add to data train\n",
    "    dummy =pd.get_dummies(dataTrain[cat],prefix=cat)\n",
    "    dataTrain = pd.concat([dataTrain, dummy], axis=1, join_axes=[dataTrain.index])\n",
    "    \n",
    "    # Add to data test\n",
    "    dummy =pd.get_dummies(dataTest[cat],prefix=cat)\n",
    "    dataTest = pd.concat([dataTest, dummy], axis=1, join_axes=[dataTest.index])\n",
    "    \n",
    "    # Add to nu\n",
    "    nu.extend(dummy.columns.tolist())\n",
    "    \n",
    "## Nominal\n",
    "for cat in catNominal.keys():\n",
    "    \n",
    "    # Get domains\n",
    "    dom = catNominal[cat]\n",
    "    \n",
    "    # Add to data train\n",
    "    catNum = [dom.index(x) for x in dataTrain[cat].fillna('NA')  ]\n",
    "    dataTrain[cat+'_Num'] = pd.Series(catNum, index=dataTrain.index)\n",
    "    \n",
    "    # Add to data test\n",
    "    catNum = [dom.index(x) for x in dataTest[cat].fillna('NA')  ]\n",
    "    dataTest[cat+'_Num'] = pd.Series(catNum, index=dataTest.index)\n",
    "    \n",
    "    # Add to nu\n",
    "    nu.append(cat+'_Num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation\n",
    "pearson  = dataTrain[nu].corr('pearson' )\n",
    "spearman = dataTrain[nu].corr('spearman')\n",
    "pearson  =  pearson[tr]\n",
    "spearman = spearman[tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data selection\n",
    "umb = 0.5\n",
    "select_pearson  = pearson [ pearson > umb].dropna().abs().sort_values(tr).index.tolist()\n",
    "select_spearman = spearman[spearman > umb].dropna().abs().sort_values(tr).index.tolist()\n",
    "select_nu = [x for x in select_spearman if x in select_pearson]\n",
    "\n",
    "df = dataTrain[ select_nu ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymean = df['SalePrice'].mean()\n",
    "ystd  = df['SalePrice'].std ()\n",
    "df = (df-df.mean())/df.std()\n",
    "\n",
    "x = df[ select_nu[:-1] ].values\n",
    "y = df[ select_nu[ -1] ].values.reshape(-1, 1)\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Linear Regression:\n",
      "MAE = 0.3000885840727423 \tMSE = 0.22620592910759893 \tRMSE = 0.47048755895692307\n"
     ]
    }
   ],
   "source": [
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = LinearRegression()\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Python Linear Regression:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Gradient Descent:\n",
      "MAE = 0.5863927274195377 \tMSE = 0.7225175854281825 \tRMSE = 0.8440437179855252\n"
     ]
    }
   ],
   "source": [
    "def BatchGradientDescent(x_train,y_train,x_test):\n",
    "    \n",
    "    # Parameters\n",
    "    alpha     = 0.001\n",
    "    err       = 1000\n",
    "    errNorm   = 1000\n",
    "    threshold = 0.001\n",
    "    \n",
    "    n_predictor = len(x_train[0])\n",
    "    n_samples   = len(y_train   )\n",
    "    theta = np.zeros([n_predictor + 1,1])\n",
    "    \n",
    "    # Train Loop\n",
    "    while (errNorm>threshold):\n",
    "        exErr = err\n",
    "        err   = 0\n",
    "        \n",
    "        # Cost function\n",
    "        y_pred = np.dot(x_train,theta[:-1]) + theta[:][-1]\n",
    "        J =  (1.0/n_samples)*  np.dot( x_train.T, y_train - y_pred)\n",
    "        \n",
    "        # Theta calculation\n",
    "        for i in range( n_predictor ):\n",
    "            theta[i] = theta[i] + alpha *np.dot(x_train[:][i],J)  \n",
    "        \n",
    "        # Error\n",
    "        err = np.sum(np.abs(y_train - y_pred))\n",
    "        \n",
    "        # Update error\n",
    "        errNorm = np.abs(exErr - err)/np.abs(err)\n",
    "        \n",
    "    return np.dot(x_test,theta[:][:-1]) + theta[:][-1]\n",
    "\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Stochastic Gradient Descent\n",
    "    y_pred = BatchGradientDescent(x_train,y_train,x_test)\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Batch Gradient Descent:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent:\n",
      "MAE = 2.82009190892894 \tMSE = 11.882498066806201 \tRMSE = 3.4365704725104345\n"
     ]
    }
   ],
   "source": [
    "def StochasticGradientDescent(x_train,y_train,x_test):\n",
    "    \n",
    "    # Parameters\n",
    "    alpha     = 0.001\n",
    "    err       = 1000\n",
    "    errNorm   = 1000\n",
    "    threshold = 0.001\n",
    "    \n",
    "    theta = np.zeros( len(x_train[0]) + 1 )\n",
    "    \n",
    "    # Train Loop\n",
    "    while (errNorm>threshold):\n",
    "        \n",
    "        exErr = err\n",
    "        err   = 0\n",
    "        for xs, ys in zip(x,y):\n",
    "            xs = np.append(xs,1)\n",
    "            y_pred = theta * xs\n",
    "            \n",
    "            # Theta\n",
    "            theta  = theta + alpha * (ys - y_pred) * xs\n",
    "            \n",
    "            # Error\n",
    "            err = err + np.sum(np.abs(ys - y_pred))\n",
    "            \n",
    "        # Update error\n",
    "        errNorm = np.abs(exErr - err)/np.abs(err)\n",
    "        \n",
    "    return np.dot(x_test,theta[:][:-1]) + theta[:][-1]\n",
    "\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Stochastic Gradient Descent\n",
    "    y_pred = StochasticGradientDescent(x_train,y_train,x_test)\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Stochastic Gradient Descent:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor:\n",
      "MAE = 0.2505450847472453 \tMSE = 0.16222980298818174 \tRMSE = 0.39681870002120256\n"
     ]
    }
   ],
   "source": [
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = RandomForestRegressor(random_state=0,n_estimators=100)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x_train,y_train)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Random Forest Regressor:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor:\n",
      "MAE = 0.239698397369006 \tMSE = 0.14351731685081806 \tRMSE = 0.3735532901593111\n"
     ]
    }
   ],
   "source": [
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = GradientBoostingRegressor(random_state=0,n_estimators=100)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x_train,y_train)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Gradient Boosting Regressor:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO Regression:\n",
      "MAE = 0.30008320396275884 \tMSE = 0.22620597221658456 \tRMSE = 0.47049196614300115\n"
     ]
    }
   ],
   "source": [
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = linear_model.Lasso(alpha=0.0001)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('LASSO Regression:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLS Regression:\n",
      "MAE = 0.3001638922817262 \tMSE = 0.22636666670173694 \tRMSE = 0.4706946935787867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = PLSRegression(n_components=5)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('PLS Regression:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian process regression :\n",
      "MAE = 0.001221215071517864 \tMSE = 0.00010873629281634567 \tRMSE = 0.009570662607088866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = GaussianProcessRegressor(random_state=0)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Gaussian process regression :')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huber Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huber Regressor:\n",
      "MAE = 0.2880854197491488 \tMSE = 0.23538884564241686 \tRMSE = 0.4792958896527335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = HuberRegressor()\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Huber Regressor:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANSAC Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSAC Regressor:\n",
      "MAE = 0.32915613089884255 \tMSE = 0.30771823606979287 \tRMSE = 0.5513455041477547\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RANSACRegressor\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = RANSACRegressor(random_state=0)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('RANSAC Regressor:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Regression:\n",
      "MAE = 0.2872772078654843 \tMSE = 0.24156908598881385 \tRMSE = 0.486137715919148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = LinearSVR(random_state=0, tol=1e-8)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Linear Support Vector Regression:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nu Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nu Support Vector Regression:\n",
      "MAE = 0.2030232177659145 \tMSE = 0.1164613149885 \tRMSE = 0.33595599333945453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import NuSVR\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = NuSVR(tol=1e-6)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Nu Support Vector Regression:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon-Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon-Support Vector Regression:\n",
      "MAE = 0.20021509858652248 \tMSE = 0.11582261133183468 \tRMSE = 0.3349649439352046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "MAE = list(); MSE = list(); RMSE = list()\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    # Select\n",
    "    x_train = x[train]; y_train = y[train]\n",
    "    x_test  = x[test ]; y_test  = y[test ]\n",
    "    \n",
    "    # Regression\n",
    "    regr = SVR(tol=1e-6)\n",
    "    \n",
    "    # Train\n",
    "    regr.fit(x,y)\n",
    "    \n",
    "    # Test\n",
    "    y_pred = regr.predict( x_test )\n",
    "    \n",
    "    # Metrics\n",
    "    MAE .append(        metrics.mean_absolute_error(y_test, y_pred) )\n",
    "    MSE .append(        metrics.mean_squared_error (y_test, y_pred) )\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error (y_test, y_pred)))\n",
    "    \n",
    "print('Epsilon-Support Vector Regression:')\n",
    "print('MAE =',np.average(MAE),'\\tMSE =',np.average(MSE),'\\tRMSE =',np.average(RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
